{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install timm torchinfo\n!pip install timm torchinfo git+https://github.com/openai/CLIP.git","metadata":{"execution":{"iopub.status.busy":"2022-10-09T12:54:22.365146Z","iopub.execute_input":"2022-10-09T12:54:22.366373Z","iopub.status.idle":"2022-10-09T12:54:46.176740Z","shell.execute_reply.started":"2022-10-09T12:54:22.366252Z","shell.execute_reply":"2022-10-09T12:54:46.175509Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting timm\n  Downloading timm-0.6.11-py3-none-any.whl (548 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.7/548.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting torchinfo\n  Downloading torchinfo-1.7.1-py3-none-any.whl (22 kB)\nRequirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.7/site-packages (from timm) (1.11.0)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.7/site-packages (from timm) (0.7.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.12.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from timm) (6.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.7->timm) (4.1.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (2.27.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (4.11.4)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (4.64.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (3.6.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (9.1.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (1.21.6)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub->timm) (3.8.0)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (1.26.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2022.6.15)\nInstalling collected packages: torchinfo, timm\nSuccessfully installed timm-0.6.11 torchinfo-1.7.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting git+https://github.com/openai/CLIP.git\n  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-blivisyr\n  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-blivisyr\n  Resolved https://github.com/openai/CLIP.git to commit d50d76daa670286dd6cacf3bcd80b5e4823fc8e1\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: timm in /opt/conda/lib/python3.7/site-packages (0.6.11)\nRequirement already satisfied: torchinfo in /opt/conda/lib/python3.7/site-packages (1.7.1)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from timm) (6.0)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.7/site-packages (from timm) (0.7.0)\nRequirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.7/site-packages (from timm) (1.11.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.12.0)\nCollecting ftfy\n  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from clip==1.0) (2021.11.10)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from clip==1.0) (4.64.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.7->timm) (4.1.1)\nRequirement already satisfied: wcwidth>=0.2.5 in /opt/conda/lib/python3.7/site-packages (from ftfy->clip==1.0) (0.2.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (3.6.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (4.11.4)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (2.27.1)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (9.1.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (1.21.6)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub->timm) (3.8.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (1.26.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2022.6.15)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (3.3)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2.0.12)\nBuilding wheels for collected packages: clip\n  Building wheel for clip (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369409 sha256=f03920e856fbb5ecb5530b028577f4605ca659d112cf8fae7a278238ef130955\n  Stored in directory: /tmp/pip-ephem-wheel-cache-vt79b4ma/wheels/fd/b9/c3/5b4470e35ed76e174bff77c92f91da82098d5e35fd5bc8cdac\nSuccessfully built clip\nInstalling collected packages: ftfy, clip\nSuccessfully installed clip-1.0 ftfy-6.1.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import timm\nimport torch\nimport torch.nn as nn\nimport torchvision\nfrom torchvision import models\nfrom torchvision import transforms  \nimport torch.nn.functional as F\nfrom sklearn.decomposition import PCA\nimport numpy as np\nimport os\nfrom tqdm import tqdm ","metadata":{"execution":{"iopub.status.busy":"2022-10-09T12:54:46.179425Z","iopub.execute_input":"2022-10-09T12:54:46.180069Z","iopub.status.idle":"2022-10-09T12:54:53.969386Z","shell.execute_reply.started":"2022-10-09T12:54:46.180029Z","shell.execute_reply":"2022-10-09T12:54:53.967131Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# model = timm.create_model(\"swin_large_patch4_window12_384_in22k\", pretrained=True, num_classes=0)    \n# model.to('cuda')\n# print('ee')","metadata":{"execution":{"iopub.status.busy":"2022-10-09T02:36:43.850988Z","iopub.execute_input":"2022-10-09T02:36:43.851444Z","iopub.status.idle":"2022-10-09T02:36:43.859156Z","shell.execute_reply.started":"2022-10-09T02:36:43.851408Z","shell.execute_reply":"2022-10-09T02:36:43.857910Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import clip\nfrom clip.clip import _download, _MODELS\n\n# clip_code = 'ViT-L/14@336px'\n# model_path = _download(_MODELS[clip_code], os.path.expanduser(\"~/.cache/clip\"))\n# with open(model_path, 'rb') as opened_file:\n#     clip_vit = torch.jit.load(opened_file, map_location=\"cuda:0\").visual.eval()\n# model = clip_vit\nmodel = timm.create_model('convnext_xlarge_in22k', pretrained=True, num_classes=0)\nmodel.to('cuda')","metadata":{"execution":{"iopub.status.busy":"2022-10-09T12:54:53.973062Z","iopub.execute_input":"2022-10-09T12:54:53.973596Z","iopub.status.idle":"2022-10-09T12:55:44.401749Z","shell.execute_reply.started":"2022-10-09T12:54:53.973565Z","shell.execute_reply":"2022-10-09T12:55:44.400747Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Downloading: \"https://dl.fbaipublicfiles.com/convnext/convnext_xlarge_22k_224.pth\" to /root/.cache/torch/hub/checkpoints/convnext_xlarge_22k_224.pth\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"ConvNeXt(\n  (stem): Sequential(\n    (0): Conv2d(3, 256, kernel_size=(4, 4), stride=(4, 4))\n    (1): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n  )\n  (stages): Sequential(\n    (0): ConvNeXtStage(\n      (downsample): Identity()\n      (blocks): Sequential(\n        (0): ConvNeXtBlock(\n          (conv_dw): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n          (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (1): ConvNeXtBlock(\n          (conv_dw): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n          (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (2): ConvNeXtBlock(\n          (conv_dw): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n          (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n      )\n    )\n    (1): ConvNeXtStage(\n      (downsample): Sequential(\n        (0): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n        (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))\n      )\n      (blocks): Sequential(\n        (0): ConvNeXtBlock(\n          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (1): ConvNeXtBlock(\n          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (2): ConvNeXtBlock(\n          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n      )\n    )\n    (2): ConvNeXtStage(\n      (downsample): Sequential(\n        (0): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n        (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))\n      )\n      (blocks): Sequential(\n        (0): ConvNeXtBlock(\n          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (1): ConvNeXtBlock(\n          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (2): ConvNeXtBlock(\n          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (3): ConvNeXtBlock(\n          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (4): ConvNeXtBlock(\n          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (5): ConvNeXtBlock(\n          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (6): ConvNeXtBlock(\n          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (7): ConvNeXtBlock(\n          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (8): ConvNeXtBlock(\n          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (9): ConvNeXtBlock(\n          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (10): ConvNeXtBlock(\n          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (11): ConvNeXtBlock(\n          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (12): ConvNeXtBlock(\n          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (13): ConvNeXtBlock(\n          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (14): ConvNeXtBlock(\n          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (15): ConvNeXtBlock(\n          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (16): ConvNeXtBlock(\n          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (17): ConvNeXtBlock(\n          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (18): ConvNeXtBlock(\n          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (19): ConvNeXtBlock(\n          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (20): ConvNeXtBlock(\n          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (21): ConvNeXtBlock(\n          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (22): ConvNeXtBlock(\n          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (23): ConvNeXtBlock(\n          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (24): ConvNeXtBlock(\n          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (25): ConvNeXtBlock(\n          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (26): ConvNeXtBlock(\n          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n      )\n    )\n    (3): ConvNeXtStage(\n      (downsample): Sequential(\n        (0): LayerNorm2d((1024,), eps=1e-06, elementwise_affine=True)\n        (1): Conv2d(1024, 2048, kernel_size=(2, 2), stride=(2, 2))\n      )\n      (blocks): Sequential(\n        (0): ConvNeXtBlock(\n          (conv_dw): Conv2d(2048, 2048, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=2048)\n          (norm): LayerNorm((2048,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (1): ConvNeXtBlock(\n          (conv_dw): Conv2d(2048, 2048, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=2048)\n          (norm): LayerNorm((2048,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n        (2): ConvNeXtBlock(\n          (conv_dw): Conv2d(2048, 2048, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=2048)\n          (norm): LayerNorm((2048,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n        )\n      )\n    )\n  )\n  (norm_pre): Identity()\n  (head): Sequential(\n    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Identity())\n    (norm): LayerNorm2d((2048,), eps=1e-06, elementwise_affine=True)\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n    (drop): Dropout(p=0.0, inplace=False)\n    (fc): Identity()\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"trfs = transforms.Compose(\n    [\n        transforms.Resize([336, 336]),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711]),\n\n    ]\n) \ndataset = torchvision.datasets.ImageFolder('../input/imagenetmini-1000/imagenet-mini/train', transform = trfs)\nloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n\nembeds = []\nlabels = []","metadata":{"execution":{"iopub.status.busy":"2022-10-09T12:55:44.404178Z","iopub.execute_input":"2022-10-09T12:55:44.405221Z","iopub.status.idle":"2022-10-09T12:55:57.274614Z","shell.execute_reply.started":"2022-10-09T12:55:44.405182Z","shell.execute_reply":"2022-10-09T12:55:57.273509Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    for images, labels_ in tqdm(loader):\n        out = model(images.to('cuda'))\n        embeds.append(out)\n        labels.append(labels_)\n\nembeds = torch.cat(embeds)\nlabels = torch.cat(labels)\n\ntorch.save(embeds, 'embeds.pt')\ntorch.save(labels, 'labels.pt')","metadata":{"execution":{"iopub.status.busy":"2022-10-09T02:36:56.598488Z","iopub.execute_input":"2022-10-09T02:36:56.598889Z","iopub.status.idle":"2022-10-09T03:51:49.675017Z","shell.execute_reply.started":"2022-10-09T02:36:56.598854Z","shell.execute_reply":"2022-10-09T03:51:49.673924Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"100%|██████████| 1086/1086 [1:14:49<00:00,  4.13s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"#Compute PCA on the train embeddings matrix\npca = PCA(n_components=64)\npca.fit(embeds.cpu())\nfrom sklearn import svm\nfrom sklearn import datasets\nimport pickle\n\n\n# 保存模型\nwith open('./convnext22k.pickle', 'wb') as f:\n    pickle.dump(pca,f)\n","metadata":{"execution":{"iopub.status.busy":"2022-10-09T03:51:49.676523Z","iopub.execute_input":"2022-10-09T03:51:49.677149Z","iopub.status.idle":"2022-10-09T03:51:57.574435Z","shell.execute_reply.started":"2022-10-09T03:51:49.677109Z","shell.execute_reply":"2022-10-09T03:51:57.573476Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import os\nos.chdir('/kaggle/working')\nprint(os.getcwd())\nprint(os.listdir(\"/kaggle/working\"))\nfrom IPython.display import FileLink\nFileLink('./convnext22k.pickle')","metadata":{"execution":{"iopub.status.busy":"2022-10-09T03:51:57.576202Z","iopub.execute_input":"2022-10-09T03:51:57.576556Z","iopub.status.idle":"2022-10-09T03:51:57.585734Z","shell.execute_reply.started":"2022-10-09T03:51:57.576518Z","shell.execute_reply":"2022-10-09T03:51:57.584585Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"/kaggle/working\n['__notebook_source__.ipynb', '.virtual_documents', 'embeds.pt', 'labels.pt', 'convnext22k.pickle']\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/convnext22k.pickle","text/html":"<a href='./convnext22k.pickle' target='_blank'>./convnext22k.pickle</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"embeds = []\nlabels = []\nclip_code = 'ViT-L/14@336px'\nmodel_path = _download(_MODELS[clip_code], os.path.expanduser(\"~/.cache/clip\"))\nwith open(model_path, 'rb') as opened_file:\n    clip_vit = torch.jit.load(opened_file, map_location=\"cuda:0\").visual.eval()\nmodel = clip_vit","metadata":{"execution":{"iopub.status.busy":"2022-10-09T12:56:32.068568Z","iopub.execute_input":"2022-10-09T12:56:32.068973Z","iopub.status.idle":"2022-10-09T12:56:38.648532Z","shell.execute_reply.started":"2022-10-09T12:56:32.068941Z","shell.execute_reply":"2022-10-09T12:56:38.647527Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    for images, labels_ in tqdm(loader):\n        out = model(images.to('cuda').half())\n        embeds.append(out)\n        labels.append(labels_)\n\nembeds = torch.cat(embeds)\nlabels = torch.cat(labels)\n\ntorch.save(embeds, 'embeds.pt')\ntorch.save(labels, 'labels.pt')","metadata":{"execution":{"iopub.status.busy":"2022-10-09T12:56:38.650583Z","iopub.execute_input":"2022-10-09T12:56:38.650966Z","iopub.status.idle":"2022-10-09T13:39:30.734349Z","shell.execute_reply.started":"2022-10-09T12:56:38.650931Z","shell.execute_reply":"2022-10-09T13:39:30.733302Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"  0%|          | 0/1086 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py:1110: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\nTo keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:601.)\n  return forward_call(*input, **kwargs)\n100%|██████████| 1086/1086 [42:51<00:00,  2.37s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"#Compute PCA on the train embeddings matrix\npca = PCA(n_components=64)\npca.fit(embeds.cpu())\nfrom sklearn import svm\nfrom sklearn import datasets\nimport pickle\n\n\n# 保存模型\nwith open('./clip-vit.pickle', 'wb') as f:\n    pickle.dump(pca,f)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T13:39:30.736395Z","iopub.execute_input":"2022-10-09T13:39:30.736907Z","iopub.status.idle":"2022-10-09T13:39:33.833680Z","shell.execute_reply.started":"2022-10-09T13:39:30.736844Z","shell.execute_reply":"2022-10-09T13:39:33.832735Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import os\nos.chdir('/kaggle/working')\nprint(os.getcwd())\nprint(os.listdir(\"/kaggle/working\"))\nfrom IPython.display import FileLink\nFileLink('./clip-vit.pickle')","metadata":{"execution":{"iopub.status.busy":"2022-10-09T13:39:33.834976Z","iopub.execute_input":"2022-10-09T13:39:33.835323Z","iopub.status.idle":"2022-10-09T13:39:33.844791Z","shell.execute_reply.started":"2022-10-09T13:39:33.835290Z","shell.execute_reply":"2022-10-09T13:39:33.843728Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"/kaggle/working\n['embeds.pt', '.virtual_documents', '__notebook_source__.ipynb', 'clip-vit.pickle', 'labels.pt']\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/clip-vit.pickle","text/html":"<a href='./clip-vit.pickle' target='_blank'>./clip-vit.pickle</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"embeds.shape[1]","metadata":{"execution":{"iopub.status.busy":"2022-10-09T03:52:23.614281Z","iopub.status.idle":"2022-10-09T03:52:23.615136Z","shell.execute_reply.started":"2022-10-09T03:52:23.614887Z","shell.execute_reply":"2022-10-09T03:52:23.614911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# linear test \n#l = nn.Linear(embeds.shape[1], 64, bias=False)\n#l.weight = torch.nn.Parameter(torch.tensor(pca_comp))","metadata":{"execution":{"iopub.status.busy":"2022-10-09T03:52:23.616552Z","iopub.status.idle":"2022-10-09T03:52:23.617426Z","shell.execute_reply.started":"2022-10-09T03:52:23.617148Z","shell.execute_reply":"2022-10-09T03:52:23.617172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyModel(nn.Module):\n  def __init__(self, model_name, target_size=[224, 224], emb_dim=1536, pca_weights=None, normalize=True):\n    super().__init__()\n    self.target_size = target_size\n    \n    self.encoder = timm.create_model(model_name, pretrained=True, num_classes=0)    \n    \n    if pca_weights is None: \n        self.final = nn.AdaptiveAvgPool1d(64)\n    else: \n        self.final =  nn.Linear(emb_dim, 64, bias=False)\n        self.final.weight = torch.nn.Parameter(torch.tensor(pca_weights))\n        \n    self.normalize = normalize\n\n  def forward(self, x):\n    x = transforms.functional.resize(x,size=self.target_size)\n    x = x / 255.0\n    x = transforms.functional.normalize(x, \n                                            mean=[0.485, 0.456, 0.406], \n                                            std=[0.229, 0.224, 0.225])\n    x = self.encoder(x)\n    x = self.final(x)\n    \n    if self.normalize:\n        x = torch.nn.functional.normalize(x)\n    return x","metadata":{"execution":{"iopub.status.busy":"2022-10-09T03:52:23.618790Z","iopub.status.idle":"2022-10-09T03:52:23.619633Z","shell.execute_reply.started":"2022-10-09T03:52:23.619356Z","shell.execute_reply":"2022-10-09T03:52:23.619380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m = MyModel(\"swin_large_patch4_window12_384_in22k\", target_size=[384, 384], emb_dim=embeds.shape[1], pca_weights=pca_comp, normalize=True)\nm.eval();","metadata":{"execution":{"iopub.status.busy":"2022-10-09T03:52:23.621019Z","iopub.status.idle":"2022-10-09T03:52:23.621868Z","shell.execute_reply.started":"2022-10-09T03:52:23.621616Z","shell.execute_reply":"2022-10-09T03:52:23.621641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"saved_model = torch.jit.script(m)\nsaved_model.save('saved_model.pt')","metadata":{"execution":{"iopub.status.busy":"2022-10-09T03:52:23.623234Z","iopub.status.idle":"2022-10-09T03:52:23.624079Z","shell.execute_reply.started":"2022-10-09T03:52:23.623828Z","shell.execute_reply":"2022-10-09T03:52:23.623852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check_model = torch.jit.load('saved_model.pt')\n\nprint(check_model)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T03:52:23.625459Z","iopub.status.idle":"2022-10-09T03:52:23.626298Z","shell.execute_reply.started":"2022-10-09T03:52:23.626036Z","shell.execute_reply":"2022-10-09T03:52:23.626061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -lh","metadata":{"execution":{"iopub.status.busy":"2022-10-09T03:52:23.628646Z","iopub.status.idle":"2022-10-09T03:52:23.629410Z","shell.execute_reply.started":"2022-10-09T03:52:23.629152Z","shell.execute_reply":"2022-10-09T03:52:23.629175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from zipfile import ZipFile\n\nwith ZipFile('submission.zip','w') as zip:           \n  zip.write(\"./saved_model.pt\", arcname='saved_model.pt') ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-09T03:52:23.630833Z","iopub.status.idle":"2022-10-09T03:52:23.631595Z","shell.execute_reply.started":"2022-10-09T03:52:23.631339Z","shell.execute_reply":"2022-10-09T03:52:23.631363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -lh","metadata":{"execution":{"iopub.status.busy":"2022-10-09T03:52:23.633065Z","iopub.status.idle":"2022-10-09T03:52:23.633878Z","shell.execute_reply.started":"2022-10-09T03:52:23.633618Z","shell.execute_reply":"2022-10-09T03:52:23.633644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchinfo import summary\n\ntest_input_size = (2, 3, 384, 384)  # the model should work with any input_size\nsummary(model, input_size=test_input_size)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T03:52:23.635294Z","iopub.status.idle":"2022-10-09T03:52:23.636080Z","shell.execute_reply.started":"2022-10-09T03:52:23.635822Z","shell.execute_reply":"2022-10-09T03:52:23.635847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"saved_model = torch.jit.load('saved_model.pt').cuda()\ninput = torch.ones(test_input_size, device='cuda')\n\nassert saved_model(input).shape == torch.Size([2, 64])","metadata":{"execution":{"iopub.status.busy":"2022-10-09T03:52:23.637531Z","iopub.status.idle":"2022-10-09T03:52:23.638322Z","shell.execute_reply.started":"2022-10-09T03:52:23.638067Z","shell.execute_reply":"2022-10-09T03:52:23.638091Z"},"trusted":true},"execution_count":null,"outputs":[]}]}