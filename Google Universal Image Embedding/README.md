This is a competition requires participants to develop a model which can transfer images to features. And the sponsor will retrieve database images based on the features.  
However, the most difficult point in this competition is the lack of training dataset, which means you need to construct a personal dataset or just ensemble some pretrained models without finetune.  
I'v tried to train a model with ResNet-ibn as the backbone on a dataset found in Discussion. But most datasets I found doesn't have instance labels, which the test images focusing on. Therefore, I got a terrible score on public leaderbroad, even the model has a great performance in training dataset.  
Then I try to ensemble the pretrained models without training. For this competition, I choose CLIP-ViT and ConvNeXt as backbone and ensemble them. Then using average pooling to reduce the dimension to 64. There is another way for dimension reduction: pca. Some participants share their ideas and codes about it, and get a higher score with this trick. However, I train pca model on two different image datasets, but only find a poorer score than before.
