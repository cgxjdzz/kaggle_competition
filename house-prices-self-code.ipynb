{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%matplotlib inline\n%config Completer.use_jedi = False\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils import data\nfrom matplotlib_inline import backend_inline\nfrom matplotlib import pyplot as plt\nimport math\n# from transformers import pipeline\n#!pip install d2l\n#from d2l import torch as d2l","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-12T15:02:54.054913Z","iopub.execute_input":"2022-09-12T15:02:54.055288Z","iopub.status.idle":"2022-09-12T15:02:54.084810Z","shell.execute_reply.started":"2022-09-12T15:02:54.055256Z","shell.execute_reply":"2022-09-12T15:02:54.083568Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    global num_inputs, num_outputs, num_hiddens1, num_hiddens2, dropout1, dropout2\n    '''\n    the net framework\n    '''\n    def __init__(self, num_inputs, num_outputs, num_hiddens1, num_hiddens2, dropout1, dropout2):\n        super(Net, self).__init__()\n        self.num_inputs = num_inputs\n        self.lin1 = nn.Linear(num_inputs, num_hiddens1)\n        self.lin2 = nn.Linear(num_hiddens1, num_hiddens2)\n        self.lin3 = nn.Linear(num_hiddens2, num_outputs)\n        self.relu = nn.ReLU()\n        self.dropout1 = dropout1\n        self.dropout2 = dropout2 \n\n        \n    def forward(self, X):\n        X = self.relu(self.lin1(X.reshape((-1, self.num_inputs))))\n        # 在全连接层之后添加一个dropout层\n        X = F.dropout(X, self.dropout1)\n        X = self.relu(self.lin2(X))\n        X = F.dropout(X, self.dropout2)\n        X = self.lin3(X)\n        return X\n\n","metadata":{"execution":{"iopub.status.busy":"2022-09-12T15:02:54.086919Z","iopub.execute_input":"2022-09-12T15:02:54.089503Z","iopub.status.idle":"2022-09-12T15:02:54.104806Z","shell.execute_reply.started":"2022-09-12T15:02:54.089463Z","shell.execute_reply":"2022-09-12T15:02:54.102739Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"'''\nread data and pretreatment\n'''\ntrain_data = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\ntest_data = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\n\nval_data, train_data = train_data.iloc[:round(0.2*train_data.shape[0]),:], train_data.iloc[round(0.2*train_data.shape[0]):,:]\n'''\nnumerical feature pretreatment respectively\n'''\n\ndef numeric_pretreatment_fillna(all_features):\n    numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n    \n    '''apply log in big feature'''\n    big_feature = ['LotArea','MiscVal']\n    all_features[big_feature] = all_features[big_feature].astype(float).apply(\n        lambda x: np.log10((x+0.001)))\n    \n    ''''''\n    del_feature = ['MoSold','YrSold']\n    all_features.drop(del_feature,axis=1)\n    \n    all_features[numeric_features] = all_features[numeric_features].apply(\n        lambda x: (x - x.mean()) / (x.std()))\n    \n    #delete some columns that full of NA\n    all_features.dropna(thresh=0.9*all_features.shape[1],axis=1)\n    \n    \n    all_features[numeric_features] = all_features[numeric_features].fillna(all_features[numeric_features].median())\n    return all_features\n\ntrain_features, val_features, test_features = train_data.iloc[:, 1:-1], val_data.iloc[:, 1:-1], test_data.iloc[:, 1:]\ntrain_features, val_features, test_features = numeric_pretreatment_fillna(train_features), numeric_pretreatment_fillna(val_features), numeric_pretreatment_fillna(test_features)\n\n'''\nnon-numerical feature pretreatment\n'''\n# “Dummy_na=True”将“na”（缺失值）视为有效的特征值，并为其创建指示符特征\nall_features = pd.concat((train_features, val_features, test_features))\nall_features = pd.get_dummies(all_features, dummy_na=True)\n#all_features.shape\n'''\ndivide train and test dataset \n''' \nn_train = train_data.shape[0]\nn_val = val_data.shape[0]\ntrain_features = torch.tensor(all_features[:n_train].values, dtype=torch.float32)\nval_features = torch.tensor(all_features[n_train:n_train+n_val].values, dtype=torch.float32)\ntest_features = torch.tensor(all_features[n_train+n_val:].values, dtype=torch.float32)\n\ndef label_zscore(label):\n    label_mean = label.mean()\n    label_std = np.std(label)\n    label = (label-label_mean)/label_std\n    return label\ntrain_label_mean = (train_data.SalePrice.values.reshape(-1, 1)).mean()\ntrain_label_std = np.std(train_data.SalePrice.values.reshape(-1, 1))\ntrain_labels = torch.tensor(label_zscore(train_data.SalePrice.values.reshape(-1, 1)), dtype=torch.float32)\nval_labels = torch.tensor(label_zscore(val_data.SalePrice.values.reshape(-1, 1)), dtype=torch.float32)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T15:02:54.107583Z","iopub.execute_input":"2022-09-12T15:02:54.109216Z","iopub.status.idle":"2022-09-12T15:02:54.518959Z","shell.execute_reply.started":"2022-09-12T15:02:54.109179Z","shell.execute_reply":"2022-09-12T15:02:54.517924Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"'''\nsome small and limited functions from Li Mu \n'''\ndef load_array(data_arrays, batch_size, is_train=True):\n    \"\"\"构造一个PyTorch数据迭代器\n    Defined in :numref:`sec_linear_concise`\"\"\"\n    dataset = data.TensorDataset(*data_arrays)\n    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n\n\ndef log_rmse(net, features, labels):\n    # 为了在取对数时进一步稳定该值，将小于1的值设置为1\n    net.eval()\n    clipped_preds = torch.clamp(net(features), 1, float('inf'))\n    rmse = torch.sqrt(loss((clipped_preds),\n                           (labels)))\n    return rmse.item()\n\n\ndef d2l_plot(X, Y=None, xlabel=None, ylabel=None, legend=None, xlim=None,\n         ylim=None, xscale='linear', yscale='linear',\n         fmts=('-', 'm--', 'g-.', 'r:'), figsize=(3.5, 2.5), axes=None):\n    \"\"\"绘制数据点\n    Defined in :numref:`sec_calculus`\"\"\"\n    def use_svg_display():\n        \"\"\"使用svg格式在Jupyter中显示绘图\n        Defined in :numref:`sec_calculus`\"\"\"\n        backend_inline.set_matplotlib_formats('svg')\n\n    def set_figsize(figsize=(3.5, 2.5)):\n        \"\"\"设置matplotlib的图表大小\n        Defined in :numref:`sec_calculus`\"\"\"\n        use_svg_display()\n        plt.rcParams['figure.figsize'] = figsize\n        \n    def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n        \"\"\"设置matplotlib的轴\n        Defined in :numref:`sec_calculus`\"\"\"\n        axes.set_xlabel(xlabel)\n        axes.set_ylabel(ylabel)\n        axes.set_xscale(xscale)\n        axes.set_yscale(yscale)\n        axes.set_xlim(xlim)\n        axes.set_ylim(ylim)\n        if legend:\n            axes.legend(legend)\n        axes.grid()\n    \n    if legend is None:\n        legend = []\n\n    set_figsize(figsize)\n    axes = axes if axes else plt.gca()\n    \n    # 如果X有一个轴，输出True\n    def has_one_axis(X):\n        return (hasattr(X, \"ndim\") and X.ndim == 1 or isinstance(X, list)\n                and not hasattr(X[0], \"__len__\"))\n\n    if has_one_axis(X):\n        X = [X]\n    if Y is None:\n        X, Y = [[]] * len(X), X\n    elif has_one_axis(Y):\n        Y = [Y]\n    if len(X) != len(Y):\n        X = X * len(Y)\n    axes.cla()\n    for x, y, fmt in zip(X, Y, fmts):\n        if len(x):\n            axes.plot(x, y, fmt)\n        else:\n            axes.plot(y, fmt)\n    set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-12T15:10:40.800697Z","iopub.execute_input":"2022-09-12T15:10:40.801247Z","iopub.status.idle":"2022-09-12T15:10:40.816002Z","shell.execute_reply.started":"2022-09-12T15:10:40.801212Z","shell.execute_reply":"2022-09-12T15:10:40.815033Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"def train(model, input_optimizer,train_features, train_labels, val_features, val_labels,\n          num_epochs, learning_rate, batch_size,loss, weight_decay):\n    '''\n    function to train model\n    \n    model: input network\n    input_optimizer: a optimizer without parameters\n    train_features,train_labels,test_features,test_labels: tensor with these data\n    num_epoches: int, epoch number\n    learning_rate: function, can change with the increase of epoch\n    batch_size: int, the size of a batch\n    loss: function,loss function\n    '''\n    global device\n    train_ls, val_ls = [], []\n    train_iter = load_array((train_features, train_labels), batch_size)\n    val_iter = load_array((val_features, val_labels), batch_size)\n    optimizer = input_optimizer(model.parameters(), lr=learning_rate(0), weight_decay = weight_decay)\n    best_val_score = 1000000\n    for epoch in range(num_epochs):\n        for X, y in train_iter:\n            X, y = X.to(device), y.to(device)\n            optimizer = input_optimizer(model.parameters(), lr=learning_rate(epoch))\n            optimizer.zero_grad()\n            model.train()\n            l = loss(model(X), y)\n            l.backward()\n            optimizer.step()\n        train_ls.append(log_rmse(model, train_features.to(device), train_labels.to(device)))\n        val_score=log_rmse(model, val_features.to(device), val_labels.to(device))\n        val_ls.append(val_score)\n        if best_val_score > val_score:\n            best_val_score = val_score\n            best_net = model\n            \n    return train_ls, val_ls, best_net\n\n\ndef train_and_pred(optimizer,train_features, val_features, test_features, train_labels, val_labels, test_data,\n                   num_epochs, learning_rate, batch_size, loss, weight_decay):\n    global num_inputs, num_outputs, num_hiddens1, num_hiddens2, dropout1, dropout2, device, train_label_mean, train_label_std\n    net = Net(num_inputs, num_outputs, num_hiddens1, num_hiddens2, dropout1, dropout2).to(device)\n    train_ls, val_ls, best_net= train(net, optimizer, train_features, train_labels, val_features, val_labels,\n                                      num_epochs, learning_rate, batch_size, loss, weight_decay)\n    d2l_plot(np.arange(1, num_epochs + 1), [train_ls,val_ls], xlabel='epoch',\n             ylabel='log rmse', xlim=[1, num_epochs], yscale='log')\n\n    print(f'训练log rmse：{float(train_ls[-1]):f}')\n    print(f'验证log rmse：{float(min(val_ls)):f}')\n    # 将网络应用于测试集。\n    best_net.eval()\n    preds = best_net(test_features.to(device)).detach().cpu().numpy()\n    # 将其重新格式化以导出到Kaggle\n    preds = (train_label_std*preds.reshape(1, -1)[0])+train_label_mean\n    test_data['SalePrice'] = pd.Series(preds)\n    submission = pd.concat([test_data['Id'], test_data['SalePrice']], axis=1)\n    submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T15:10:43.562998Z","iopub.execute_input":"2022-09-12T15:10:43.563676Z","iopub.status.idle":"2022-09-12T15:10:43.586090Z","shell.execute_reply.started":"2022-09-12T15:10:43.563634Z","shell.execute_reply":"2022-09-12T15:10:43.584908Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"'''\nk-fold function, written by Li Mu\n'''\ndef get_k_fold_data(k, i, X, y):\n    assert k > 1\n    fold_size = X.shape[0] // k\n    X_train, y_train = None, None\n    for j in range(k):\n        idx = slice(j * fold_size, (j + 1) * fold_size)\n        X_part, y_part = X[idx, :], y[idx]\n        if j == i:\n            X_valid, y_valid = X_part, y_part\n        elif X_train is None:\n            X_train, y_train = X_part, y_part\n        else:\n            X_train = torch.cat([X_train, X_part], 0)\n            y_train = torch.cat([y_train, y_part], 0)\n    return X_train, y_train, X_valid, y_valid\n\n\ndef k_fold(k, X_train, y_train, num_epochs, learning_rate, input_optimizer, loss,\n           batch_size):\n    global num_inputs, num_outputs, num_hiddens1, num_hiddens2, dropout1, dropout2\n    train_l_sum, valid_l_sum = 0, 0\n    for i in range(k):\n        data = get_k_fold_data(k, i, X_train, y_train)\n        net = Net(num_inputs, num_outputs, num_hiddens1, num_hiddens2, dropout1, dropout2).to(device)\n        train_ls, valid_ls = train(net, input_optimizer, *data, num_epochs, learning_rate,\n                                   batch_size, loss=loss)\n        train_l_sum += train_ls[-1]\n        valid_l_sum += valid_ls[-1]\n        if i == 0:\n            d2l_plot(list(range(1, num_epochs + 1)), [train_ls, valid_ls],\n                     xlabel='epoch', ylabel='rmse', xlim=[1, num_epochs],\n                     legend=['train', 'valid'], yscale='log')\n        print(f'折{i + 1}，训练log rmse{float(train_ls[-1]):f}, '\n              f'验证log rmse{float(valid_ls[-1]):f}')\n    return train_l_sum / k, valid_l_sum / k","metadata":{"execution":{"iopub.status.busy":"2022-09-12T15:02:54.586341Z","iopub.execute_input":"2022-09-12T15:02:54.588661Z","iopub.status.idle":"2022-09-12T15:02:54.606975Z","shell.execute_reply.started":"2022-09-12T15:02:54.588623Z","shell.execute_reply":"2022-09-12T15:02:54.605775Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"'''\nsome hyperparameters settings\n'''\n\ndevice=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nepochs, start_decline_epochs =400, 30\nweight_decay =  5\nnum_inputs, num_outputs, num_hiddens1, num_hiddens2, dropout1, dropout2 = 331, 1, 512, 64, 0, 0\nmodel = Net(num_inputs, num_outputs, num_hiddens1, num_hiddens2, dropout1, dropout2).to(device)\noptimizer = torch.optim.Adam\nloss = nn.SmoothL1Loss()\nbatch_size = 128\nk = 5\n\ndef learning_rate(temp_epochs):\n    global epochs,start_decline_epochs\n    if temp_epochs < start_decline_epochs: return 5e-6\n    else: \n        return 5e-6*math.cos((temp_epochs-start_decline_epochs)/(epochs-start_decline_epochs)*math.pi/2)\n    \ndef learning_rate(temp_epochs):\n    global epochs,start_decline_epochs\n    if temp_epochs < start_decline_epochs: return 1e-5\n    else: \n        return 1e-5-1e-5 *(temp_epochs)/epochs\n\n#train_l, valid_l = k_fold(k, train_features, train_labels, epochs, learning_rate, optimizer,\n#                         loss, batch_size)\n#print(f'{k}-折验证: 平均训练log rmse: {float(train_l):f}, '\n#      f'平均验证log rmse: {float(valid_l):f}')\n      \ntrain_and_pred(optimizer,train_features, val_features, test_features, train_labels, val_labels, test_data,\n               epochs, learning_rate, batch_size, loss,weight_decay)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T16:11:14.984675Z","iopub.execute_input":"2022-09-12T16:11:14.985806Z","iopub.status.idle":"2022-09-12T16:11:25.469665Z","shell.execute_reply.started":"2022-09-12T16:11:14.985750Z","shell.execute_reply":"2022-09-12T16:11:25.468744Z"},"trusted":true},"execution_count":162,"outputs":[]},{"cell_type":"markdown","source":"在label做zscore处理后，dropout会使学习曲线波动明显\n好看的学习率曲线","metadata":{}}]}