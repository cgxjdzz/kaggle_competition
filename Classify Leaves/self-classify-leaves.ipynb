{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install timm\n!pip install ttach","metadata":{"execution":{"iopub.status.busy":"2022-09-20T12:41:30.825179Z","iopub.execute_input":"2022-09-20T12:41:30.825539Z","iopub.status.idle":"2022-09-20T12:41:51.647841Z","shell.execute_reply.started":"2022-09-20T12:41:30.825508Z","shell.execute_reply":"2022-09-20T12:41:51.646648Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Collecting timm\n  Downloading timm-0.6.7-py3-none-any.whl (509 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.0/510.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from timm) (1.11.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (4.3.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (1.21.6)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (2.28.1)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (9.1.1)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->timm) (2.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->timm) (2022.6.15.2)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->timm) (1.26.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->timm) (3.3)\nInstalling collected packages: timm\nSuccessfully installed timm-0.6.7\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting ttach\n  Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\nInstalling collected packages: ttach\nSuccessfully installed ttach-0.0.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport cv2\nimport time\nimport math\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport pandas as pd \nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom torch.optim import Adam, AdamW\nfrom torch.nn.parameter import Parameter\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom sklearn import metrics\nimport urllib\nimport pickle\nimport torch.nn.functional as F\nimport seaborn as sns\nimport random\nimport sys\nimport gc\nimport shutil\nfrom tqdm.autonotebook import tqdm\nimport albumentations\nfrom albumentations import pytorch as AT\nfrom matplotlib import pyplot as plt\nimport scipy.special\nsigmoid = lambda x: scipy.special.expit(x)\nfrom scipy.special import softmax\nfrom sklearn.preprocessing import LabelEncoder\n#import torch.utils as tu \nimport timm\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport ttach as tta","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-20T12:41:53.439155Z","iopub.execute_input":"2022-09-20T12:41:53.439548Z","iopub.status.idle":"2022-09-20T12:41:54.210517Z","shell.execute_reply.started":"2022-09-20T12:41:53.439514Z","shell.execute_reply":"2022-09-20T12:41:54.209235Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"'''\n从timm扒来的抽象代码，知道了怎么用，不过具体的还没有怎么看。作用是mixup和cutmix\n'''\ndef one_hot(x, num_classes, on_value=1., off_value=0., device='cuda'):\n    x = x.long().view(-1, 1)\n    return torch.full((x.size()[0], num_classes), off_value, device=device).scatter_(1, x, on_value)\n\n\ndef mixup_target(target, num_classes, lam=1., smoothing=0.0, device='cuda'):\n    off_value = smoothing / num_classes\n    on_value = 1. - smoothing + off_value\n    y1 = one_hot(target, num_classes, on_value=on_value, off_value=off_value, device=device)\n    y2 = one_hot(target.flip(0), num_classes, on_value=on_value, off_value=off_value, device=device)\n    return y1 * lam + y2 * (1. - lam)\n\n\ndef mixup_target_multi_binary(target, lam=1., smoothing=0.0, device='cuda'):\n    target = target * (1. - smoothing) + smoothing / 2.\n    y1 = target.to(device)\n    y2 = target.flip(0).to(device)\n    return y1 * lam + y2 * (1. - lam)\n\n\ndef rand_bbox(img_shape, lam, margin=0., count=None):\n    \"\"\" Standard CutMix bounding-box\n    Generates a random square bbox based on lambda value. This impl includes\n    support for enforcing a border margin as percent of bbox dimensions.\n    Args:\n        img_shape (tuple): Image shape as tuple\n        lam (float): Cutmix lambda value\n        margin (float): Percentage of bbox dimension to enforce as margin (reduce amount of box outside image)\n        count (int): Number of bbox to generate\n    \"\"\"\n    ratio = np.sqrt(1 - lam)\n    img_h, img_w = img_shape[-2:]\n    cut_h, cut_w = int(img_h * ratio), int(img_w * ratio)\n    margin_y, margin_x = int(margin * cut_h), int(margin * cut_w)\n    cy = np.random.randint(0 + margin_y, img_h - margin_y, size=count)\n    cx = np.random.randint(0 + margin_x, img_w - margin_x, size=count)\n    yl = np.clip(cy - cut_h // 2, 0, img_h)\n    yh = np.clip(cy + cut_h // 2, 0, img_h)\n    xl = np.clip(cx - cut_w // 2, 0, img_w)\n    xh = np.clip(cx + cut_w // 2, 0, img_w)\n    return yl, yh, xl, xh\n\n\ndef rand_bbox_minmax(img_shape, minmax, count=None):\n    \"\"\" Min-Max CutMix bounding-box\n    Inspired by Darknet cutmix impl, generates a random rectangular bbox\n    based on min/max percent values applied to each dimension of the input image.\n    Typical defaults for minmax are usually in the  .2-.3 for min and .8-.9 range for max.\n    Args:\n        img_shape (tuple): Image shape as tuple\n        minmax (tuple or list): Min and max bbox ratios (as percent of image size)\n        count (int): Number of bbox to generate\n    \"\"\"\n    assert len(minmax) == 2\n    img_h, img_w = img_shape[-2:]\n    cut_h = np.random.randint(int(img_h * minmax[0]), int(img_h * minmax[1]), size=count)\n    cut_w = np.random.randint(int(img_w * minmax[0]), int(img_w * minmax[1]), size=count)\n    yl = np.random.randint(0, img_h - cut_h, size=count)\n    xl = np.random.randint(0, img_w - cut_w, size=count)\n    yu = yl + cut_h\n    xu = xl + cut_w\n    return yl, yu, xl, xu\n\n\ndef cutmix_bbox_and_lam(img_shape, lam, ratio_minmax=None, correct_lam=True, count=None):\n    \"\"\" Generate bbox and apply lambda correction.\n    \"\"\"\n    if ratio_minmax is not None:\n        yl, yu, xl, xu = rand_bbox_minmax(img_shape, ratio_minmax, count=count)\n    else:\n        yl, yu, xl, xu = rand_bbox(img_shape, lam, count=count)\n    if correct_lam or ratio_minmax is not None:\n        bbox_area = (yu - yl) * (xu - xl)\n        lam = 1. - bbox_area / float(img_shape[-2] * img_shape[-1])\n    return (yl, yu, xl, xu), lam\n\n\nclass Mixup:\n    \"\"\" \n    Mixup/Cutmix that applies different params to each element or whole batch\n    Args:\n        mixup_alpha (float): mixup alpha value, mixup is active if > 0.\n        cutmix_alpha (float): cutmix alpha value, cutmix is active if > 0.\n        cutmix_minmax (List[float]): cutmix min/max image ratio, cutmix is active and uses this vs alpha if not None.\n        prob (float): probability of applying mixup or cutmix per batch or element\n        switch_prob (float): probability of switching to cutmix instead of mixup when both are active\n        mode (str): how to apply mixup/cutmix params (per 'batch', 'pair' (pair of elements), 'elem' (element)\n        correct_lam (bool): apply lambda correction when cutmix bbox clipped by image borders\n        onehot (bool): whether one hot dtype Long label input or float multi-hot or soft label\n        label_smoothing (float): apply label smoothing to the mixed target tensor\n        num_classes (int): number of classes for target\n    Examples::\n        >>> mixup, cutmix = 0.35, 0.15\n        >>> prob = mixup + cutmix\n        >>> switch_prob = cutmix / prob\n        >>> mixup_fn = Mixup(prob=prob, switch_prob=switch_prob, onthot=False, label_smoothing=0.0)\n        >>> for batch_idx, (input, target) in enumerate(loader):\n        >>>     input, target = input.cuda(), target.cuda()\n        >>>     input, target = mixup_fn(input, target)\n    \"\"\"\n\n    def __init__(self, mixup_alpha=0.2, cutmix_alpha=1.0, cutmix_minmax=None, prob=0.2, switch_prob=0.3,\n                 mode='elem', correct_lam=True, onehot=True, label_smoothing=0.0, num_classes=1000):\n        self.mixup_alpha = mixup_alpha\n        self.cutmix_alpha = cutmix_alpha\n        self.cutmix_minmax = cutmix_minmax\n        if self.cutmix_minmax is not None:\n            assert len(self.cutmix_minmax) == 2\n            # force cutmix alpha == 1.0 when minmax active to keep logic simple & safe\n            self.cutmix_alpha = 1.0\n        self.mix_prob = prob\n        self.switch_prob = switch_prob\n        self.onehot = onehot\n        self.label_smoothing = label_smoothing\n        self.num_classes = num_classes\n        self.mode = mode\n        self.correct_lam = correct_lam  # correct lambda based on clipped area for cutmix\n        self.mixup_enabled = True  # set to false to disable mixing (intended tp be set by train loop)\n\n    def _params_per_elem(self, batch_size):\n        lam = np.ones(batch_size, dtype=np.float32)\n        use_cutmix = np.zeros(batch_size, dtype=np.bool)\n        if self.mixup_enabled:\n            if self.mixup_alpha > 0. and self.cutmix_alpha > 0.:\n                use_cutmix = np.random.rand(batch_size) < self.switch_prob\n                lam_mix = np.where(\n                    use_cutmix,\n                    np.random.beta(self.cutmix_alpha, self.cutmix_alpha, size=batch_size),\n                    np.random.beta(self.mixup_alpha, self.mixup_alpha, size=batch_size))\n            elif self.mixup_alpha > 0.:\n                lam_mix = np.random.beta(self.mixup_alpha, self.mixup_alpha, size=batch_size)\n            elif self.cutmix_alpha > 0.:\n                use_cutmix = np.ones(batch_size, dtype=np.bool)\n                lam_mix = np.random.beta(self.cutmix_alpha, self.cutmix_alpha, size=batch_size)\n            else:\n                assert False, \"One of mixup_alpha > 0., cutmix_alpha > 0., cutmix_minmax not None should be true.\"\n            lam = np.where(np.random.rand(batch_size) < self.mix_prob, lam_mix.astype(np.float32), lam)\n        return lam, use_cutmix\n\n    def _params_per_batch(self):\n        lam = 1.\n        use_cutmix = False\n        if self.mixup_enabled and np.random.rand() < self.mix_prob:\n            if self.mixup_alpha > 0. and self.cutmix_alpha > 0.:\n                use_cutmix = np.random.rand() < self.switch_prob\n                lam_mix = np.random.beta(self.cutmix_alpha, self.cutmix_alpha) if use_cutmix else \\\n                    np.random.beta(self.mixup_alpha, self.mixup_alpha)\n            elif self.mixup_alpha > 0.:\n                lam_mix = np.random.beta(self.mixup_alpha, self.mixup_alpha)\n            elif self.cutmix_alpha > 0.:\n                use_cutmix = True\n                lam_mix = np.random.beta(self.cutmix_alpha, self.cutmix_alpha)\n            else:\n                assert False, \"One of mixup_alpha > 0., cutmix_alpha > 0., cutmix_minmax not None should be true.\"\n            lam = float(lam_mix)\n        return lam, use_cutmix\n\n    def _mix_elem(self, x):\n        batch_size = len(x)\n        lam_batch, use_cutmix = self._params_per_elem(batch_size)\n        x_orig = x.clone()  # need to keep an unmodified original for mixing source\n        for i in range(batch_size):\n            j = batch_size - i - 1\n            lam = lam_batch[i]\n            if lam != 1.:\n                if use_cutmix[i]:\n                    (yl, yh, xl, xh), lam = cutmix_bbox_and_lam(\n                        x[i].shape, lam, ratio_minmax=self.cutmix_minmax, correct_lam=self.correct_lam)\n                    x[i][:, yl:yh, xl:xh] = x_orig[j][:, yl:yh, xl:xh]\n                    lam_batch[i] = lam\n                else:\n                    x[i] = x[i] * lam + x_orig[j] * (1 - lam)\n        return torch.tensor(lam_batch, device=x.device, dtype=x.dtype).unsqueeze(1)\n\n    def _mix_pair(self, x):\n        batch_size = len(x)\n        lam_batch, use_cutmix = self._params_per_elem(batch_size // 2)\n        x_orig = x.clone()  # need to keep an unmodified original for mixing source\n        for i in range(batch_size // 2):\n            j = batch_size - i - 1\n            lam = lam_batch[i]\n            if lam != 1.:\n                if use_cutmix[i]:\n                    (yl, yh, xl, xh), lam = cutmix_bbox_and_lam(\n                        x[i].shape, lam, ratio_minmax=self.cutmix_minmax, correct_lam=self.correct_lam)\n                    x[i][:, yl:yh, xl:xh] = x_orig[j][:, yl:yh, xl:xh]\n                    x[j][:, yl:yh, xl:xh] = x_orig[i][:, yl:yh, xl:xh]\n                    lam_batch[i] = lam\n                else:\n                    x[i] = x[i] * lam + x_orig[j] * (1 - lam)\n                    x[j] = x[j] * lam + x_orig[i] * (1 - lam)\n        lam_batch = np.concatenate((lam_batch, lam_batch[::-1]))\n        return torch.tensor(lam_batch, device=x.device, dtype=x.dtype).unsqueeze(1)\n\n    def _mix_batch(self, x):\n        lam, use_cutmix = self._params_per_batch()\n        if lam == 1.:\n            return 1.\n        if use_cutmix:\n            (yl, yh, xl, xh), lam = cutmix_bbox_and_lam(\n                x.shape, lam, ratio_minmax=self.cutmix_minmax, correct_lam=self.correct_lam)\n            x[:, :, yl:yh, xl:xh] = x.flip(0)[:, :, yl:yh, xl:xh]\n        else:\n            x_flipped = x.flip(0).mul_(1. - lam)\n            x.mul_(lam).add_(x_flipped)\n        return lam\n\n    def __call__(self, x, target):\n        assert len(x) % 2 == 0, 'Batch size should be even when using this'\n        if self.mode == 'elem':\n            lam = self._mix_elem(x)\n        elif self.mode == 'pair':\n            lam = self._mix_pair(x)\n        else:\n            lam = self._mix_batch(x)\n        if self.onehot:\n            target = mixup_target(target, self.num_classes, lam, self.label_smoothing, device=x.device)\n        else:\n            target = mixup_target_multi_binary(target, lam, self.label_smoothing, device=x.device)\n        return x, target\n","metadata":{"execution":{"iopub.status.busy":"2022-09-20T12:41:59.120374Z","iopub.execute_input":"2022-09-20T12:41:59.120866Z","iopub.status.idle":"2022-09-20T12:41:59.181713Z","shell.execute_reply.started":"2022-09-20T12:41:59.120824Z","shell.execute_reply":"2022-09-20T12:41:59.180614Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"'''\n随机旋转90°，转置，翻转，平移缩放旋转\n'''\ntrain_transform = albumentations.Compose([\n    albumentations.RandomRotate90(p=0.5),\n    albumentations.Transpose(p=0.5),\n    albumentations.Flip(p=0.5),\n    albumentations.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.0625, rotate_limit=45, border_mode=1, p=0.5),\n#     albumentations.OneOf([\n#             albumentations.Blur(blur_limit=4, p=1),\n#             albumentations.MotionBlur(blur_limit=4, p=1),\n#             albumentations.MedianBlur(blur_limit=4, p=1)\n#         ], p=0.5),\n    albumentations.Normalize(),\n    AT.ToTensorV2(),\n    ])\n    \ntest_transform = albumentations.Compose([\n    albumentations.Normalize(),\n    AT.ToTensorV2(),\n    ])\n\n\nclass LeavesDataset(Dataset):\n    '''\n    读取并创建训练集、测试集\n    '''\n    def __init__(self, csv, transform = train_transform):\n        self.csv = csv\n        self.transform = transform\n  \n    def __len__(self):\n        return len(self.csv['image'])\n  \n    def __getitem__(self, idx):\n        img = cv2.imread('../input/classify-leaves/' + self.csv['image'][idx])\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        label = self.csv['label'][idx]\n        if self.transform:\n            img = self.transform(image = img)['image']\n        return img, torch.tensor(label).type(torch.LongTensor)\n\n    \nclass LeavesTestDataset(Dataset):\n    '''\n    读取并创建测试集\n    '''\n    def __init__(self, csv, transform = test_transform):\n        self.csv = csv\n        self.transform = transform\n  \n    def __len__(self):\n        return len(self.csv['image'])\n    \n    def __getitem__(self, idx):\n        img = cv2.imread('../input/classify-leaves/' + self.csv['image'][idx])\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            img = self.transform(image = img)['image']\n        return img\n","metadata":{"execution":{"iopub.status.busy":"2022-09-20T12:42:03.061294Z","iopub.execute_input":"2022-09-20T12:42:03.061967Z","iopub.status.idle":"2022-09-20T12:42:03.073826Z","shell.execute_reply.started":"2022-09-20T12:42:03.061931Z","shell.execute_reply":"2022-09-20T12:42:03.072610Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"'''\nhyperparameter\n'''\nSEED = 42\nCLASSES = 176\nFOLD = 5\nEPOCH = 10\nMIXUP = 0.1 # 0 to 1\nbatch_size = 64\ntest_batch_size = 8\n#设置种子 3407 is all you need！\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\nnp.random.seed(SEED)\nrandom.seed(SEED)\ntorch.backends.cudnn.deterministic = True\n\nbase_dir = '../input/classify-leaves'\ntrain_df = pd.read_csv(os.path.join(base_dir, 'train.csv'))\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-20T13:00:21.748162Z","iopub.execute_input":"2022-09-20T13:00:21.748557Z","iopub.status.idle":"2022-09-20T13:00:21.781185Z","shell.execute_reply.started":"2022-09-20T13:00:21.748525Z","shell.execute_reply":"2022-09-20T13:00:21.780327Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"          image             label\n0  images/0.jpg  maclura_pomifera\n1  images/1.jpg  maclura_pomifera\n2  images/2.jpg  maclura_pomifera\n3  images/3.jpg  maclura_pomifera\n4  images/4.jpg  maclura_pomifera","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>images/0.jpg</td>\n      <td>maclura_pomifera</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>images/1.jpg</td>\n      <td>maclura_pomifera</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>images/2.jpg</td>\n      <td>maclura_pomifera</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>images/3.jpg</td>\n      <td>maclura_pomifera</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>images/4.jpg</td>\n      <td>maclura_pomifera</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"'''\n随机划分训练集和验证集\n'''\ncsv = pd.read_csv('../input/classify-leaves/train.csv')\n#保证训练集验证集集类别比例相同的kfold\nlabelencoder = LabelEncoder()\norigin_label = csv['label']\nlabelencoder.fit(origin_label)\ntransform_label = labelencoder.transform(origin_label)\ncsv['label'] = transform_label\nsfolder = StratifiedKFold(n_splits=FOLD,random_state=SEED,shuffle=True)\ntrain_folds = []\nval_folds = []\nfor train_idx, val_idx in sfolder.split(csv['image'], transform_label):\n    train_folds.append(train_idx)\n    val_folds.append(val_idx)\n    print(len(train_idx), len(val_idx))","metadata":{"execution":{"iopub.status.busy":"2022-09-20T12:42:06.788464Z","iopub.execute_input":"2022-09-20T12:42:06.789167Z","iopub.status.idle":"2022-09-20T12:42:06.833149Z","shell.execute_reply.started":"2022-09-20T12:42:06.789129Z","shell.execute_reply":"2022-09-20T12:42:06.832233Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"14682 3671\n14682 3671\n14682 3671\n14683 3670\n14683 3670\n","output_type":"stream"}]},{"cell_type":"code","source":"'''\n如果不用mixup的话就使用label-smoothing就可以了，这个函数(以及nn自带的crossentropy）默认导入的target是int不是one-hot编码。\n如果用了mixup，那么在其中的mixup_target（timm包）会自动加上label-smoothing。之后被混合的图片的target会由两个数据的target混合在一起。\n'''\nclass SoftTargetCrossEntropy(nn.Module):\n\n    def __init__(self):\n        super(SoftTargetCrossEntropy, self).__init__()\n\n    def forward(self, x, target):\n        loss = torch.sum(-target * F.log_softmax(x, dim=-1), dim=-1)\n        return loss.mean()\n\n\nclass LabelSmoothing(nn.Module):\n    \"\"\"NLL loss with label smoothing.\n    \"\"\"\n    def __init__(self, smoothing=0.0):\n        \"\"\"Constructor for the LabelSmoothing module.\n        :param smoothing: label smoothing factor\n        \"\"\"\n        super(LabelSmoothing, self).__init__()\n        self.confidence = 1.0 - smoothing\n        self.smoothing = smoothing\n\n    def forward(self, x, target):\n        logprobs = torch.nn.functional.log_softmax(x, dim=-1)\n        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n        nll_loss = nll_loss.squeeze(1)\n        smooth_loss = -logprobs.mean(dim=-1)\n        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n        return loss.mean()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-09-20T12:42:09.641934Z","iopub.execute_input":"2022-09-20T12:42:09.642288Z","iopub.status.idle":"2022-09-20T12:42:09.653532Z","shell.execute_reply.started":"2022-09-20T12:42:09.642257Z","shell.execute_reply":"2022-09-20T12:42:09.652223Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"'''\n首先设置非常小的学习率，然后训练一个batch，看看loss是多少。之后逐渐增大学习率，查看loss变化。因为较小的lr对网络中参数的影响对于更大的lr而言可以忽略不记，所以每个batch都近似于用该学习率进行初始的训练。\n详见Cyclical Learning Rates for Training Neural Networks中的3.3节。\n'''\n\ndef find_lr(model, factor, train_dl, optimizer, loss_fn, device, init_lr=1e-8, final_lr=1e-1, beta=0.98, plot=True, save_dir=None):\n    num = len(train_dl) - 1\n    mult = (final_lr / init_lr) ** (1/num)\n    lr = init_lr\n    optimizer.param_groups[0]['lr'] = lr\n    avg_loss = 0.\n    best_loss = 0.\n    batch_num = 0\n    losses = []\n    log_lrs = []\n    scaler = torch.cuda.amp.GradScaler() # for 0\n\n    if 1:\n          for x, y in train_dl:\n            x, y = x.to(device), y.to(device)\n            batch_num += 1\n            optimizer.zero_grad()\n            #混合精度计算\n            with torch.cuda.amp.autocast():\n                out = model(x)\n                loss = loss_fn(out, y)\n              #smoothen the loss\n            avg_loss = beta * avg_loss + (1-beta) * loss.data.item() #check\n            smoothed_loss = avg_loss / (1 - beta**batch_num) #bias correction\n              #stop if loss explodes\n            if batch_num > 1 and smoothed_loss > 4 * best_loss: #prevents explosion\n                  break\n              #record the best loss\n            if smoothed_loss < best_loss or batch_num == 1:\n                  best_loss = smoothed_loss\n              #store the values\n            losses.append(smoothed_loss)\n            log_lrs.append(math.log10(lr))\n              #sgd 算法来调整learning rate\n              #loss.backward()\n              #optimizer.step()\n            scaler.scale(loss).backward() #计算梯度\n            scaler.step(optimizer) #调整lr\n            scaler.update() #更新梯度\n              #update the lr for the next step\n            lr *= mult\n            optimizer.param_groups[0]['lr'] = lr\n    #Suggest a learning rate\n    log_lrs, losses = np.array(log_lrs), np.array(losses)\n    idx_min = np.argmin(losses)\n    min_log_lr = log_lrs[idx_min]\n    lr_auto = (10 ** (min_log_lr)) /factor\n    if plot:\n        selected = [np.argmin(np.abs(log_lrs - (min_log_lr-1)))] #highlight the suggested lr 但是这suggested lr是怎么来的，很令人困惑。\n        plt.figure()\n        plt.plot(log_lrs, losses,'-gD', markevery=selected)\n        plt.xlabel('log_lrs')\n        plt.ylabel('loss')\n        plt.title('LR Range Test')\n        if save_dir is not None:\n            plt.savefig(f'{save_dir}/lr_range_test.png')\n        else:\n            plt.savefig(f'lr_range_test.png')\n    return lr_auto","metadata":{"execution":{"iopub.status.busy":"2022-09-20T09:00:35.509240Z","iopub.execute_input":"2022-09-20T09:00:35.509914Z","iopub.status.idle":"2022-09-20T09:00:35.525394Z","shell.execute_reply.started":"2022-09-20T09:00:35.509873Z","shell.execute_reply":"2022-09-20T09:00:35.524486Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# lr_suggested = find_lr(model, 100, train_dataloader, optimizer, loss_fn, 'cuda', init_lr=1e-10, final_lr=1.) #run if u want suggestion from autolr","metadata":{"execution":{"iopub.status.busy":"2022-09-20T09:00:35.527124Z","iopub.execute_input":"2022-09-20T09:00:35.527624Z","iopub.status.idle":"2022-09-20T09:00:35.539614Z","shell.execute_reply.started":"2022-09-20T09:00:35.527588Z","shell.execute_reply":"2022-09-20T09:00:35.538631Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"'''\n一个外挂的储存超参数的函数。lr_scheduler 是在训练过程中可以对lr进行调整的类（比我那个lr函数不知道高到哪里去了）。\n'''\ndef get_learner(lr, nb, epochs, model_name='resnet50d', MIXUP=0.1):\n    mixup_fn = Mixup(prob=MIXUP, switch_prob=0.0, onehot=True, label_smoothing=0.05, num_classes=len(set(transform_label)))\n    model = timm.create_model(model_name, pretrained=True)\n    ###预训练模型也可以改每一层的结构和参数。其中最后的一层fc输出数量和本项目不一样，所以进行改动\n    model.fc = nn.Linear(model.fc.in_features, len(set(transform_label)))\n    #当网络变化较大时，初始化会使模型更加稳定，xavier_uniform 均匀分布\n    nn.init.xavier_uniform_(model.fc.weight)\n    model.cuda()\n\n    params_1x = [param for name, param in model.named_parameters()\n              if name not in [\"fc.weight\", \"fc.bias\"]]\n\n    optimizer = torch.optim.AdamW([{'params': params_1x},\n                                    {'params': model.fc.parameters(),\n                                      'lr': lr*10}],\n                                  lr=lr, weight_decay=2e-4)\n\n    loss_fn = SoftTargetCrossEntropy() if MIXUP else LabelSmoothing(0.1)\n    loss_fn_test = F.cross_entropy\n    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs*nb, eta_min=lr/20)\n    return model, optimizer, loss_fn, loss_fn_test, lr_scheduler, mixup_fn\n\n#model = torchvision.models.resnet50(pretrained=True)\n#model = torchvision.models.resnext101_32x8d(pretrained=True)\n#model = timm.create_model('seresnext50_32x4d', pretrained=True)\n#model = timm.create_model('resnet50d', pretrained=True)\n#model = timm.create_model('resnest50d', pretrained=True)\n#model = timm.create_model('tf_efficientnetv2_l_in21ft1k', pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-20T13:00:39.156446Z","iopub.execute_input":"2022-09-20T13:00:39.156825Z","iopub.status.idle":"2022-09-20T13:00:39.167802Z","shell.execute_reply.started":"2022-09-20T13:00:39.156795Z","shell.execute_reply":"2022-09-20T13:00:39.166737Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"'''\n五折交叉验证，其中GradScaler和autocast是为了AMP（混合精度训练），这个之后随便用用就不研究了。\nTTA（test time augmentation）是在测试时对测试集进行augmentation，然后对某个样本的所有图像的预测取均值或最多值。常用于图像分类，以此来增强模型的泛用性和robust等。\n其可以通过缩放或裁剪放大提取出图片的纹理或者特征来加强预测效果。\n然而，粗暴地对其进行augmentation并取均值可能会在某些类上取到反效果（corruption），因为裁剪或者缩放可能导致一些关键特征难以出现在该样本的大多数图像中。\n对此Better Aggregation in Test-Time Augmentation提出了一种更加体面的aggregation方式来聚合这些augmentation之后的测试集结果，也即为其赋予一个权重并进行学习，被称为Class-Weighted TTA\n但是搜了一下好像没有现成的库，kaggle服务器这周也用到期了，就下次一定...\n（更详细的介绍可以见推送）\n'''\ndevice = 'cuda'\nsave_dir = './'\n \nscaler = torch.cuda.amp.GradScaler() # for AMP training \ntest_csv = pd.read_csv('../input/classify-leaves/test.csv')\n\nfor fold in range(FOLD):\n    print(f'Start Fold{fold}...')\n    train_csv = csv.iloc[train_folds[fold]].reset_index()\n    val_csv = csv.iloc[val_folds[fold]].reset_index()\n    train_dataset = LeavesDataset(train_csv, train_transform)\n    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)\n    val_dataset = LeavesDataset(val_csv, train_transform)\n    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, drop_last=False)\n    model, optimizer, loss_fn, loss_fn_test, lr_scheduler, mixup_fn = get_learner(3e-4, len(train_dataloader), EPOCHS, model_name='resnet50d', MIXUP=MIXUP)\n    model_name = f'5fold_test_fold{fold}'\n    train_losses = [] \n    val_losses = []\n    train_accus = []\n    val_accus = []\n    best_accu = 0\n    best_loss = float('inf')\n    lrs = []\n    for epoch in range(EPOCHS):\n        t1 = time.time()\n        val_accu = 0\n        train_accu = 0\n        train_losses_tmp = []\n        #Train\n        model.train()\n        t_inf = 0\n        for x, y in train_dataloader:\n            if MIXUP:\n                x, y = mixup_fn(x, y)\n                x, y = x.to(device), y.to(device)\n            #Forward\n            with torch.cuda.amp.autocast():\n                x = x.to(device)\n                pred = model(x)\n                loss = loss_fn(pred, y)\n            #Backward\n            #loss.backward()\n            #optimizer.step()\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n            lr_scheduler.step()\n            optimizer.zero_grad()\n            #Statistics\n            lrs.append(optimizer.param_groups[0]['lr']) #group 0,1,2 share the learning rate\n            train_losses_tmp.append(loss.data.item())\n            pred_labels = torch.argmax(pred.data, dim=1)\n            y_labels = torch.argmax(y.data, dim=1) if MIXUP else y.data\n            train_accu += (pred_labels==y_labels).float().sum()\n        t_inf /= len(train_dataloader)\n        train_losses.append(np.mean(np.array(train_losses_tmp)))\n        train_accu /= len(train_dataset)\n        train_accus.append(train_accu.data.item())\n\n        t2 = time.time()\n        #Validation\n        val_losses_tmp = []\n        model.eval()\n        with torch.no_grad():\n            for x, y in val_dataloader:\n                x, y = x.to(device), y.to(device)\n                logit = model(x)\n                val_loss = loss_fn_test(logit, y) \n                val_losses_tmp.append(val_loss.data.item())\n                pred = torch.argmax(logit.data, dim=1)\n                val_accu += (pred==y.data).float().sum()\n        t3 = time.time()\n        val_loss = np.mean(np.array(val_losses_tmp))\n        val_losses.append(val_loss)\n        val_accu /= len(val_dataset)\n        val_accus.append(val_accu.data.item())\n        #print('fold', fold, 'epoch', epoch, 'train_loss', train_losses[epoch], 'val_loss', val_losses[epoch], 'val_accu', val_accu, 'train_accu', train_accu, 'train time', t2-t1, 'val time', t3-t2, 'lr[0]', lrs[-1])\n        if save_dir is not None:\n            if val_accu == best_accu:\n                if val_loss < best_loss: #never satisfied\n                    checkpoint = {\"model\": model.state_dict()}\n                    torch.save(checkpoint, os.path.join(save_dir,f'{model_name}_best.pth'))\n                    print(f'Stored a new best model in {save_dir}')\n                    best_loss = val_loss\n            elif val_accu > best_accu:\n                checkpoint = {\"model\": model.state_dict()}\n                torch.save(checkpoint, os.path.join(save_dir,f'{model_name}_best.pth'))\n                print(f'Stored a new best model in {save_dir}')\n                best_accu = val_accu\n    \n    #test time\n    tta_model = tta.ClassificationTTAWrapper(model, tta.aliases.flip_transform(),  merge_mode='mean')\n    tta_model.eval()\n    preds = []\n    for x in test_dataloader:\n        x = x.to(device)\n        logit = tta_model(x)\n        pred = torch.argmax(logit.data, dim=1).cpu().numpy()\n        preds += list(pred)\n    res = labelencoder.inverse_transform(preds)\n    test_csv.insert(1, 'label', res)\n    test_csv.to_csv(f'submission_e50{model_name}_fold{fold}.csv', index=False)\n    print('test cvs is saved')","metadata":{"execution":{"iopub.status.busy":"2022-09-20T13:00:41.640262Z","iopub.execute_input":"2022-09-20T13:00:41.640793Z","iopub.status.idle":"2022-09-20T13:00:44.172848Z","shell.execute_reply.started":"2022-09-20T13:00:41.640760Z","shell.execute_reply":"2022-09-20T13:00:44.171335Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Start Fold0...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_18/4288096270.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0;31m#Backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m#loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_18/530669422.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, target)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mlogprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mnll_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlogprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mnll_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0msmooth_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlogprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: gather(): Expected dtype int64 for index"],"ename":"RuntimeError","evalue":"gather(): Expected dtype int64 for index","output_type":"error"}]}]}